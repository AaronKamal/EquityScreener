{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z_Alt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import cov\n",
    "from scipy import stats\n",
    "import csv\n",
    "import glob\n",
    "#data = pd.read_csv(\"Final3.csv\")\n",
    "\n",
    "li=[]\n",
    "header = ['Sector_Name','CNAE','Number_of_Companies_Used','Number_of_Same','Number_of_Different','Accuracy','Mean','Standard_Deviation']\n",
    "\n",
    "with open('z_alt.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    f.close()\n",
    "    \n",
    "path = r'/Volumes/BEAST MODE/CSV files' # use your path\n",
    "\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    data = pd.read_csv(filename, index_col=None, header=0)\n",
    "    data.replace(to_replace = 'Limited_liability_company', value = '0', inplace = True)\n",
    "    data = data[['Company_Name','CNAE_2009_Code','NIF_Code', 'Legal_Form','Z_Alt','Z_Alt_Category','Credit_score','CS_Category_Type']]\n",
    "    data = data[~data['Legal_Form'].isin(['0'])]\n",
    "    a = data['Z_Alt']\n",
    "    p95 = np.percentile(a, 95)\n",
    "    p5 = np.percentile(a, 5)\n",
    "    #print(p95)\n",
    "    #print(p5)\n",
    "    def percentile95(row):\n",
    "        if row[\"Z_Alt\"] < p95:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    def percentile5(row):\n",
    "        if row[\"Z_Alt\"] > p5:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(per95=data.apply(percentile95, axis=1))\n",
    "    data = data.assign(per5=data.apply(percentile5, axis=1))\n",
    "    data = data[~data['per95'].isin(['0'])]\n",
    "    data = data[~data['per5'].isin(['0'])]\n",
    "\n",
    "    def z_alt_num(row):\n",
    "        if row[\"Z_Alt_Category\"] == \"Bankruptcy Imminent\":\n",
    "            return \"4\"\n",
    "        elif row[\"Z_Alt_Category\"] == \"Bankruptcy Probable\":\n",
    "            return \"3\"\n",
    "        elif row[\"Z_Alt_Category\"] == \"Bankruptcy Possible\":\n",
    "            return \"2\"\n",
    "        elif row[\"Z_Alt_Category\"] == \"Bankruptcy Improbable\":\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(Z_Alt_Number=data.apply(z_alt_num, axis=1))\n",
    "\n",
    "    def cs_num(row):\n",
    "        if row[\"CS_Category_Type\"] == \"Poor\":\n",
    "            return \"4\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Fair\":\n",
    "            return \"3\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Good\":\n",
    "            return \"2\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Very Good\":\n",
    "            return \"1\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Excellent\":\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(CS_number=data.apply(cs_num, axis=1))\n",
    "\n",
    "    def diff(row):\n",
    "        if row['Z_Alt_Number']==row['CS_number']:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "\n",
    "    data = data.assign(difference=data.apply(diff, axis=1))\n",
    "    mean_z_alt=data['Z_Alt'].mean()\n",
    "    sd_z_alt=data['Z_Alt'].std()\n",
    "    difference=data['difference'].value_counts()\n",
    "    dif0= difference['0']\n",
    "    dif1= difference['1']\n",
    "    totalused= dif0+dif1\n",
    "    accuracy= dif1/totalused\n",
    "    cnae=data['CNAE_2009_Code']\n",
    "    blank= ' '\n",
    "    finaldata=[blank,cnae,totalused,dif1,dif0,accuracy,mean_z_alt,sd_z_alt]\n",
    "    with open('z_alt.csv', 'a',newline='\\n',encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow(finaldata)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "    li.append(data)\n",
    "\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Final3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-bb5e8b97da35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final3.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samenif'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Final3.csv'"
     ]
    }
   ],
   "source": [
    "#Get rid of all revenue below 1m and 50m\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"Final3.csv\")\n",
    "df['samenif']=np.nan\n",
    "for i in range(1,(len(df)-1)):\n",
    "    if df.loc[i-1,'NIF_Code']!=df.loc[i,'NIF_Code']:\n",
    "        df.loc[i,'samenif']=1\n",
    "    else:\n",
    "        df.loc[i,'samenif']=0\n",
    "        \n",
    "df['samenif'].fillna('1.0', inplace=True)\n",
    "df= df.head(len(df)-1)\n",
    "df.drop( df[ df['samenif'] == 0.0 ].index , inplace=True)\n",
    "#df = df[~df['samenif'].isin(['0.0'])]\n",
    "df1 = df[['Company_Name','NIF_Code','samenif','Operating_Revenue/Turnover']]\n",
    "\n",
    "\n",
    "df1['millioncheck1'] = df1['Operating_Revenue/Turnover'].gt(1000000)\n",
    "df1['millioncheck50'] = df1['Operating_Revenue/Turnover'].lt(50000000)\n",
    "millioncheck1=df1.millioncheck1.value_counts()\n",
    "millioncheck50=df1.millioncheck50.value_counts()\n",
    "df1 = df1[df1['millioncheck1'] == True]\n",
    "df1 = df1[df1['millioncheck50'] == True]\n",
    "df1.millioncheck1.value_counts()\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"Final3.csv\")\n",
    "dfniflist = df1['NIF_Code'].tolist()\n",
    "\n",
    "new_df = df[df.NIF_Code.isin(dfniflist)]\n",
    "new_df.to_csv('final4.csv')\n",
    "print(millioncheck1[False])\n",
    "print(millioncheck50[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUL data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import cov\n",
    "from scipy import stats\n",
    "import csv\n",
    "import glob\n",
    "#data = pd.read_csv(\"Final3.csv\")\n",
    "\n",
    "li=[]\n",
    "header = ['Sector_Name','CNAE','Number_of_Companies_Used','Number_of_Same','Number_of_Different','Accuracy','Mean','Standard_Deviation']\n",
    "\n",
    "with open('Ful.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    f.close()\n",
    "    \n",
    "path = r'/Volumes/BEAST MODE/CSV files' # use your path\n",
    "\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    data = pd.read_csv(filename, index_col=None, header=0)\n",
    "    data = data[['Company_Name','CNAE_2009_Code','NIF_Code', 'Legal_Form','Ful','Ful_Category','Credit_score','CS_Category_Type']]\n",
    "    a = data['Ful']\n",
    "    p95 = np.percentile(a, 95)\n",
    "    p5 = np.percentile(a, 5)\n",
    "    #print(p95)\n",
    "    #print(p5)\n",
    "    def percentile95(row):\n",
    "        if row[\"Ful\"] < p95:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    def percentile5(row):\n",
    "        if row[\"Ful\"] > p5:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(per95=data.apply(percentile95, axis=1))\n",
    "    data = data.assign(per5=data.apply(percentile5, axis=1))\n",
    "    data = data[~data['per95'].isin(['0'])]\n",
    "    data = data[~data['per5'].isin(['0'])]\n",
    "\n",
    "    def z_alt_num(row):\n",
    "        if row[\"Ful_Category\"] == \"Insolvent\":\n",
    "            return \"2\"\n",
    "        elif row[\"Ful_Category\"] == \"Improbable\":\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(Ful_Number=data.apply(z_alt_num, axis=1))\n",
    "\n",
    "    def cs_num(row):\n",
    "        if row[\"CS_Category_Type\"] == \"Poor\":\n",
    "            return \"2\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Fair\":\n",
    "            return \"2\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Good\":\n",
    "            return \"1\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Very Good\":\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    \n",
    "    data = data.assign(CS_number=data.apply(cs_num, axis=1))\n",
    "\n",
    "    def diff(row):\n",
    "        if row['Ful_Number']==row['CS_number']:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "\n",
    "    data = data.assign(difference=data.apply(diff, axis=1))\n",
    "    mean_z_alt=data['Ful'].mean()\n",
    "    sd_z_alt=data['Ful'].std()\n",
    "    difference=data['difference'].value_counts()\n",
    "    dif0= difference['0']\n",
    "    dif1= difference['1']\n",
    "    totalused= dif0+dif1\n",
    "    accuracy= dif1/totalused\n",
    "    cnae=data['CNAE_2009_Code']\n",
    "    blank= ' '\n",
    "    finaldata=[blank,cnae,totalused,dif1,dif0,accuracy,mean_z_alt,sd_z_alt]\n",
    "    with open('Ful.csv', 'a',newline='\\n',encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow(finaldata)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "    li.append(data)\n",
    "\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding accuracy between poor and bankruptcy imminent\n",
    "#Z_Alt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import cov\n",
    "from scipy import stats\n",
    "import csv\n",
    "import glob\n",
    "#data = pd.read_csv(\"Final3.csv\")\n",
    "\n",
    "li=[]\n",
    "header = ['Sector_Name','CNAE','Number_of_Companies_Used','Number_of_Same','Number_of_Different','Accuracy']\n",
    "\n",
    "with open('z_alt.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    f.close()\n",
    "    \n",
    "path = r'/Volumes/BEAST MODE/CSV files' # use your path\n",
    "\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    data = pd.read_csv(filename, index_col=None, header=0)\n",
    "    data.replace(to_replace = 'Limited_liability_company', value = '0', inplace = True)\n",
    "    data = data[['Company_Name','CNAE_2009_Code','NIF_Code', 'Legal_Form','Z_Alt','Z_Alt_Category','Credit_score','CS_Category_Type']]\n",
    "    data = data[~data['Legal_Form'].isin(['0'])]\n",
    "    a = data['Z_Alt']\n",
    "    p95 = np.percentile(a, 95)\n",
    "    p5 = np.percentile(a, 5)\n",
    "    #print(p95)\n",
    "    #print(p5)\n",
    "    def percentile95(row):\n",
    "        if row[\"Z_Alt\"] < p95:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    def percentile5(row):\n",
    "        if row[\"Z_Alt\"] > p5:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(per95=data.apply(percentile95, axis=1))\n",
    "    data = data.assign(per5=data.apply(percentile5, axis=1))\n",
    "    data = data[~data['per95'].isin(['0'])]\n",
    "    data = data[~data['per5'].isin(['0'])]\n",
    "    #data.replace(to_replace = 'Bankruptcy Imminent', value = '1', inplace = True)\n",
    "    data = data[data['Z_Alt_Category'].isin(['Bankruptcy Imminent'])]\n",
    "    \n",
    "    def z_alt_num(row):\n",
    "        if row[\"Z_Alt_Category\"] == \"Bankruptcy Imminent\":\n",
    "            return \"4\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(Z_Alt_Number=data.apply(z_alt_num, axis=1))\n",
    "\n",
    "    def cs_num(row):\n",
    "        if row[\"CS_Category_Type\"] == \"Poor\":\n",
    "            return \"4\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Fair\":\n",
    "            return \"3\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Good\":\n",
    "            return \"2\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Very Good\":\n",
    "            return \"1\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Excellent\":\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(CS_number=data.apply(cs_num, axis=1))\n",
    "\n",
    "    def diff(row):\n",
    "        if row['Z_Alt_Number']==row['CS_number']:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data.to_csv('data.csv')\n",
    "    data = data.assign(difference=data.apply(diff, axis=1))\n",
    "    difference=data['difference'].value_counts()\n",
    "    dif0= difference['0']\n",
    "    dif1= difference['1']\n",
    "    totalused= dif0+dif1\n",
    "    accuracy= dif1/totalused\n",
    "    cnae=data['CNAE_2009_Code']\n",
    "    blank= ' '\n",
    "    finaldata=[blank,cnae,totalused,dif1,dif0,accuracy]\n",
    "    with open('z_alt.csv', 'a',newline='\\n',encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow(finaldata)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "    li.append(data)\n",
    "\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding accuracy between poor and bankruptcy imminent\n",
    "#FUL \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import cov\n",
    "from scipy import stats\n",
    "import csv\n",
    "import glob\n",
    "#data = pd.read_csv(\"Final3.csv\")\n",
    "\n",
    "li=[]\n",
    "header = ['Sector_Name','CNAE','Number_of_Companies_Used','Number_of_Same','Number_of_Different','Accuracy']\n",
    "\n",
    "with open('Ful.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    f.close()\n",
    "    \n",
    "path = r'/Volumes/BEAST MODE/CSV files' # use your path\n",
    "\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    data = pd.read_csv(filename, index_col=None, header=0)\n",
    "    #data.replace(to_replace = 'Limited_liability_company', value = '0', inplace = True)\n",
    "    data = data[['Company_Name','CNAE_2009_Code','NIF_Code', 'Legal_Form','Ful','Ful_Category','Credit_score','CS_Category_Type']]\n",
    "    #data = data[~data['Legal_Form'].isin(['0'])]\n",
    "    a = data['Ful']\n",
    "    p95 = np.percentile(a, 95)\n",
    "    p5 = np.percentile(a, 5)\n",
    "    #print(p95)\n",
    "    #print(p5)\n",
    "    def percentile95(row):\n",
    "        if row[\"Ful\"] < p95:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    def percentile5(row):\n",
    "        if row[\"Ful\"] > p5:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(per95=data.apply(percentile95, axis=1))\n",
    "    data = data.assign(per5=data.apply(percentile5, axis=1))\n",
    "    data = data[~data['per95'].isin(['0'])]\n",
    "    data = data[~data['per5'].isin(['0'])]\n",
    "    #data.replace(to_replace = 'Bankruptcy Imminent', value = '1', inplace = True)\n",
    "    data = data[data['Ful_Category'].isin(['Insolvent'])]\n",
    "    \n",
    "    def z_alt_num(row):\n",
    "        if row[\"Ful_Category\"] == \"Insolvent\":\n",
    "            return \"2\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(Ful_Number=data.apply(z_alt_num, axis=1))\n",
    "\n",
    "    def cs_num(row):\n",
    "        if row[\"CS_Category_Type\"] == \"Poor\":\n",
    "            return \"2\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Fair\":\n",
    "            return \"1\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Good\":\n",
    "            return \"1\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Very Good\":\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(CS_number=data.apply(cs_num, axis=1))\n",
    "\n",
    "    def diff(row):\n",
    "        if row['Ful_Number']==row['CS_number']:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data.to_csv('data.csv')\n",
    "    data = data.assign(difference=data.apply(diff, axis=1))\n",
    "    difference=data['difference'].value_counts()\n",
    "    dif0= difference['0']\n",
    "    dif1= difference['1']\n",
    "    totalused= dif0+dif1\n",
    "    accuracy= dif1/totalused\n",
    "    cnae=data['CNAE_2009_Code']\n",
    "    blank= ' '\n",
    "    finaldata=[blank,cnae,totalused,dif1,dif0,accuracy]\n",
    "    with open('Ful.csv', 'a',newline='\\n',encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow(finaldata)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "    li.append(data)\n",
    "\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding accuracy between poor and bankruptcy imminent\n",
    "#Kan \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import cov\n",
    "from scipy import stats\n",
    "import csv\n",
    "import glob\n",
    "#data = pd.read_csv(\"Final3.csv\")\n",
    "\n",
    "li=[]\n",
    "header = ['Sector_Name','CNAE','Number_of_Companies_Used','Number_of_Same','Number_of_Different','Accuracy']\n",
    "\n",
    "with open('Kan.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    f.close()\n",
    "    \n",
    "path = r'/Volumes/BEAST MODE/CSV files' # use your path\n",
    "\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    data = pd.read_csv(filename, index_col=None, header=0)\n",
    "    data.replace(to_replace = 'Improbable', value = '0', inplace = True)\n",
    "    data = data[['Company_Name','CNAE_2009_Code','NIF_Code', 'Legal_Form','Kan','Kan_Category','Credit_score','CS_Category_Type']]\n",
    "    data = data[~data['Kan_Category'].isin(['0'])]\n",
    "    a = data['Kan']\n",
    "    p95 = np.percentile(a, 95)\n",
    "    p5 = np.percentile(a, 5)\n",
    "    #print(p95)\n",
    "    #print(p5)\n",
    "    def percentile95(row):\n",
    "        if row[\"Kan\"] < p95:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    def percentile5(row):\n",
    "        if row[\"Kan\"] > p5:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(per95=data.apply(percentile95, axis=1))\n",
    "    data = data.assign(per5=data.apply(percentile5, axis=1))\n",
    "    data = data[~data['per95'].isin(['0'])]\n",
    "    data = data[~data['per5'].isin(['0'])]\n",
    "    #data.replace(to_replace = 'Bankruptcy Imminent', value = '1', inplace = True)\n",
    "    data = data[data['Kan_Category'].isin(['Insolvent'])]\n",
    "    \n",
    "    def z_alt_num(row):\n",
    "        if row[\"Kan_Category\"] == \"Insolvent\":\n",
    "            return \"2\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(Kan_Number=data.apply(z_alt_num, axis=1))\n",
    "\n",
    "    def cs_num(row):\n",
    "        if row[\"CS_Category_Type\"] == \"Poor\":\n",
    "            return \"2\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Fair\":\n",
    "            return \"1\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Good\":\n",
    "            return \"1\"\n",
    "        elif row[\"CS_Category_Type\"] == \"Very Good\":\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data = data.assign(CS_number=data.apply(cs_num, axis=1))\n",
    "\n",
    "    def diff(row):\n",
    "        if row['Kan_Number']==row['CS_number']:\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "    data.to_csv('data.csv')\n",
    "    data = data.assign(difference=data.apply(diff, axis=1))\n",
    "    difference=data['difference'].value_counts()\n",
    "    dif0= difference['0']\n",
    "    dif1= difference['1']\n",
    "    totalused= dif0+dif1\n",
    "    accuracy= dif1/totalused\n",
    "    cnae=data['CNAE_2009_Code']\n",
    "    blank= ' '\n",
    "    finaldata=[blank,cnae,totalused,dif1,dif0,accuracy]\n",
    "    with open('Kan.csv', 'a',newline='\\n',encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        writer.writerow(finaldata)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "    li.append(data)\n",
    "\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 0       7410\n",
      "1       7410\n",
      "2       7410\n",
      "3       7410\n",
      "4       7410\n",
      "        ... \n",
      "2367    7022\n",
      "2368    7022\n",
      "2369    7022\n",
      "2370    7022\n",
      "2371    7022\n",
      "Name: CNAE_2009_Code, Length: 2372, dtype: int64, 45018, 26693, 18325, 0.5929406015371629]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation between Total assets, Fixed assets, Total liabilities, Long-term debt, Shareholders funds and Credit Score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
